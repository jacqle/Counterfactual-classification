{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from pattern.en import parse, Sentence, parse, mood, modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Examples of non-counterfactual sentences (0):\n",
      "- The new request, if approved, would keep the military forces on the border through Jan.\n",
      "- Companies in financial difficulty can currently only negotiate down wages and conditions to below those established by the collective bargaining procedure if they have the approval of unions, which is rarely given.\n",
      "- If needed, I would like to have the right to try.\n",
      "\n",
      "*Examples of counterfactual sentences (1):\n",
      "- Goodfellow's theory has been questioned, however, because the plane made two other sharp turns that would've been impossible if the pilots were unconscious.\n",
      "- However, both campaigners and pro-People's Vote MPs say that this number would be grow significantly if there were no other viable means of avoiding leaving the EU without a Withdrawal Agreement.\n",
      "- Things could have been even better if the whole chip industry wasn't constrained by chip foundries such as Taiwan Semiconductor Manufacturing (NYSE: TSM) and United Microelectronics getting swamped under more orders than they can handle.\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/Léo/Desktop/semeval-2020-task-5/data/\"\n",
    "train1 = pd.read_csv(path + 'train/subtask1.csv')\n",
    "train2 = pd.read_csv(path + 'train/data_train_subtask2.csv')\n",
    "train2 = train2[[\"sentence\"]]\n",
    "train2.insert(1, \"gold_label\", \"1\") # add a column 'gold_label' with value 1 (data for subtask2 only contains counterfactuals)\n",
    "\n",
    "# concatenate data and remove duplicates\n",
    "df = pd.concat([train1, train2])\n",
    "df = df.reset_index(drop=True)\n",
    "df_gpby = df.groupby(list(df.columns))\n",
    "idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "df = df.reindex(idx)\n",
    "df['gold_label'] = df['gold_label'].apply(str)\n",
    "\n",
    "print('*Examples of non-counterfactual sentences (0):')\n",
    "for i in df.loc[df['gold_label'] == '0', 'sentence'][:3]:\n",
    "    print('- ' + i)\n",
    "    \n",
    "print('')\n",
    "print('*Examples of counterfactual sentences (1):')\n",
    "for i in df.loc[df['gold_label'] == '1', 'sentence'][:3]:\n",
    "    print('- ' + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "Experimenting with different preprocessing steps showed that cleaning the sentences was best kept to a minimum. We only keep alphanumeric tokens, lowercase them and merge them with their corresponding part-of-speech tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodfellow_NNP 's_POS theory_NN has_VBZ been_VBN questioned_VBN however_RB because_IN the_DT plane_NN made_VBD two_CD other_JJ sharp_JJ turns_NNS that_WDT would_MD 've_VB been_VBN impossible_JJ if_IN the_DT pilots_NNS were_VBD unconscious_JJ\n",
      "NNP POS NN VBZ VBN VBN RB IN DT NN VBD CD JJ JJ NNS WDT MD VB VBN JJ IN DT NNS VBD JJ\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# set custom stop words list\n",
    "stopwords = {'could','are','be','been','can','cannot','could','did','do','does','done','get','had','has',\n",
    "             'have','if','is','made','might','must','should','were','will','would'}\n",
    "nlp.Defaults.stop_words -= stopwords\n",
    "\n",
    "token_pos = []\n",
    "pos = []\n",
    "for i in df['sentence']:\n",
    "    sent = nlp(i)\n",
    "    tokens_tags = [token.lower_ + '_' + token.tag_ for token in sent if not token.is_punct and not token.is_space] \n",
    "    tags = [token.tag_ for token in sent if not token.is_punct and not token.is_space]\n",
    "    token_pos.append(' '.join(tokens_tags))\n",
    "    pos.append(' '.join(tags))\n",
    "    \n",
    "df['sent_tok'] = token_pos\n",
    "df['sent_pos'] = pos\n",
    "\n",
    "print(df['sent_tok'].iloc[0])\n",
    "print(df['sent_pos'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding lexical information\n",
    "\n",
    "Some ngrams have been selected based on a chi-squared test that was previously conducted (see keyword2.py). It was noted that specifically adding them as one-hot encoded features did not affect the results. Their presence in a sentence will be encapsulated by the vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léo\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "ngrams_list = ['would', 'say', 'I', \"'s\", 'may', 'Mr.', 'even', 'year', 'get', 'take', 'Trump', 'company', 'see', 'market', 'use', 'also', 'wish', 'Mr', 'need', 'ask', 'new', 'come', 'much', 'want', 'government', 'patient', 'risk', 'bank', 'change',\n",
    "'I would', 'Mr. Trump', 'I wish', 'I could', 'year ago', 'I know', 'wish I', 'last year', 'I I', 'euro zone', 'central bank', 'probably would',\n",
    "'I wish I', 'health care provider', 'I I would', 'wish I could', 'think I would', 'I probably would', 'year ago I']\n",
    "\n",
    "# One-hot encoding statistically relevant ngrams\n",
    "for gram in ngrams_list:\n",
    "    df[gram] = 0\n",
    "    for idx, sentence in enumerate(df['sentence']):\n",
    "        if gram in sentence:\n",
    "            df[gram].iloc[idx] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding syntactic information\n",
    "\n",
    "Since the construction of counterfactuals is intricately tied with the use of specific verb forms, frequent sequences of POS tags containing at least one verb are considered as an additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common trigrams: (0,1)\n",
      "('PRP', 'MD', 'VB')  : 0.38  |  ('MD', 'VB', 'VBN')  : 0.65\n",
      "('MD', 'VB', 'VBN')  : 0.28  |  ('PRP', 'MD', 'VB')  : 0.44\n",
      "('NN', 'MD', 'VB')  : 0.25  |  ('IN', 'PRP', 'VBD')  : 0.3\n",
      "('MD', 'RB', 'VB')  : 0.23  |  ('MD', 'RB', 'VB')  : 0.2\n",
      "('VB', 'DT', 'NN')  : 0.22  |  ('NN', 'MD', 'VB')  : 0.17\n",
      "('MD', 'VB', 'DT')  : 0.18  |  ('VB', 'VBN', 'DT')  : 0.16\n",
      "('NNS', 'MD', 'VB')  : 0.17  |  ('VBN', 'IN', 'DT')  : 0.15\n",
      "('VBN', 'IN', 'DT')  : 0.15  |  ('VBN', 'DT', 'NN')  : 0.13\n",
      "('TO', 'VB', 'DT')  : 0.14  |  ('VB', 'VBN', 'IN')  : 0.13\n",
      "('MD', 'VB', 'IN')  : 0.14  |  ('PRP', 'VBD', 'VBN')  : 0.12\n",
      "('IN', 'PRP', 'VBD')  : 0.13  |  ('NNS', 'MD', 'VB')  : 0.11\n",
      "('NNP', 'NNP', 'VBD')  : 0.13  |  ('VBD', 'DT', 'NN')  : 0.11\n",
      "('IN', 'PRP', 'VBP')  : 0.12  |  ('RB', 'VB', 'VBN')  : 0.11\n",
      "('NN', 'TO', 'VB')  : 0.12  |  ('PRP', 'VBD', 'RB')  : 0.11\n",
      "('NNP', 'MD', 'VB')  : 0.11  |  ('DT', 'NN', 'VBD')  : 0.1\n",
      "Most common fourgrams: (0,1)\n",
      "('VB', 'DT', 'NN', 'IN')  : 0.09  |  ('PRP', 'MD', 'VB', 'VBN')  : 0.25\n",
      "('DT', 'NN', 'MD', 'VB')  : 0.09  |  ('MD', 'VB', 'VBN', 'DT')  : 0.13\n",
      "('PRP', 'MD', 'RB', 'VB')  : 0.09  |  ('NN', 'MD', 'VB', 'VBN')  : 0.11\n",
      "('MD', 'VB', 'DT', 'NN')  : 0.09  |  ('MD', 'RB', 'VB', 'VBN')  : 0.1\n",
      "('IN', 'PRP', 'MD', 'VB')  : 0.09  |  ('MD', 'VB', 'VBN', 'IN')  : 0.1\n",
      "('MD', 'VB', 'VBN', 'IN')  : 0.08  |  ('PRP', 'MD', 'RB', 'VB')  : 0.09\n",
      "('TO', 'VB', 'DT', 'NN')  : 0.07  |  ('NN', 'PRP', 'MD', 'VB')  : 0.09\n",
      "('VBN', 'IN', 'DT', 'NN')  : 0.07  |  ('IN', 'PRP', 'VBD', 'VBN')  : 0.09\n",
      "('NN', 'MD', 'VB', 'VBN')  : 0.07  |  ('DT', 'NN', 'MD', 'VB')  : 0.07\n",
      "('PRP', 'MD', 'VB', 'DT')  : 0.07  |  ('NNS', 'MD', 'VB', 'VBN')  : 0.07\n"
     ]
    }
   ],
   "source": [
    "trigram0 = {}\n",
    "trigram1 = {}\n",
    "fourgram0 = {}\n",
    "fourgram1 = {}\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "# Counting POS tags trigrams and fourgrams that contain a verb\n",
    "for idx, sent in enumerate(df['sent_pos']):\n",
    "    tri = ngrams(sent.split(), 3)  \n",
    "    four = ngrams(sent.split(), 4)\n",
    "    if df['gold_label'].iloc[idx] == '0':\n",
    "        count0 += 1  \n",
    "        for i in tri:\n",
    "            if 'V' in ' '.join(i):\n",
    "                trigram0[i] = trigram0.get(i, 0) + 1\n",
    "        for i in four:\n",
    "            if 'V' in ' '.join(i):\n",
    "                fourgram0[i] = fourgram0.get(i, 0) + 1\n",
    "    else: \n",
    "        count1 += 1\n",
    "        for i in tri:\n",
    "            if 'V' in ' '.join(i):\n",
    "                trigram1[i] = trigram1.get(i, 0) + 1\n",
    "        for i in four:\n",
    "            if 'V' in ' '.join(i):\n",
    "                fourgram1[i] = fourgram1.get(i, 0) + 1\n",
    "\n",
    "# Scaling these numbers down for easier comparison\n",
    "trigram0 = {k: round((v/count0), 2) for k,v in trigram0.items()}\n",
    "trigram1 = {k: round((v/count1), 2) for k,v in trigram1.items()}\n",
    "fourgram0 = {k: round((v/count0), 2) for k,v in fourgram0.items()}\n",
    "fourgram1 = {k: round((v/count1), 2) for k,v in fourgram1.items()}\n",
    "\n",
    "# Using Counter objects to retrieve the most common values of a dict\n",
    "trigram0 = Counter(trigram0) \n",
    "trigram1 = Counter(trigram1) \n",
    "fourgram0 = Counter(fourgram0) \n",
    "fourgram1 = Counter(fourgram1) \n",
    "high_tri0 = trigram0.most_common(15)                  \n",
    "high_tri1 = trigram1.most_common(15)  \n",
    "high_four0 = fourgram0.most_common(10)  \n",
    "high_four1 = fourgram1.most_common(10)  \n",
    "\n",
    "def encode_common_seq(top_seqs, ngram_range):\n",
    "    # One-hot encoding the presence of the most common POS tags sequences\n",
    "    for seq, count in top_seqs:\n",
    "        df[seq[0]] = 0 \n",
    "        for idx, sent in enumerate(df['sent_pos']):\n",
    "            grams = list(ngrams(sent.split(), ngram_range))  \n",
    "            if seq in grams:\n",
    "                df[seq[0]].iloc[idx] = 1\n",
    "            \n",
    "encode_common_seq(high_tri0, 3)\n",
    "encode_common_seq(high_tri1, 3)\n",
    "encode_common_seq(high_four0, 4)\n",
    "encode_common_seq(high_four1, 4)\n",
    "                    \n",
    "print('Most common trigrams: (0,1)')\n",
    "for i,j  in zip(high_tri0, high_tri1): \n",
    "    print(i[0],\" :\",i[1],\" | \", j[0],\" :\",j[1])\n",
    "\n",
    "print('Most common fourgrams: (0,1)')\n",
    "for i,j  in zip(high_four0, high_four1): \n",
    "    print(i[0],\" :\",i[1],\" | \", j[0],\" :\",j[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding semantic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom embeddings\n",
    "Using the library Gensim, we are able to train our custom word embeddings on the dataset using Word2Vec, since the corpus at hand is relatively small. Words with similar meanings appear close to each other in the vector space (see below the words related to ‘if’). In order to produce a single vector for one training example (i.e. a sentence), we can sum all the words and average them, thereby obtaining a vector representation of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('though', 0.75510573387146),\n",
       " ('\"if', 0.7416023015975952),\n",
       " ('up,', 0.7197611331939697),\n",
       " ('unless', 0.7177684307098389),\n",
       " ('assuming', 0.7159310579299927),\n",
       " ('once', 0.6934325695037842)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_length = 300\n",
    "model = Word2Vec(sentences=[sent.lower().split() for sent in df['sentence']], \n",
    "                 sg=1, \n",
    "                 size=vector_length,  \n",
    "                 workers=1)\n",
    "\n",
    "def vectorize(sentences, model):\n",
    "    # Sum all word vectors and average them to obtain a representation of the sentence\n",
    "    all_vect = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        vectors = []\n",
    "        for w in words: \n",
    "            if w not in model.wv.vocab:\n",
    "                vectors.append(np.zeros(vector_length))\n",
    "            else:\n",
    "                vectors.append(model.wv[w])                    \n",
    "        avg = sum(vectors)/len(vectors)\n",
    "        all_vect.append(avg)\n",
    "    return all_vect\n",
    "\n",
    "vectorized_sentences = vectorize(df['sentence'], model)\n",
    "custom_embeddings = {}\n",
    "for i in range(vector_length):\n",
    "    custom_embeddings[i] = [val[i] for val in vectorized_sentences]\n",
    "    \n",
    "model.wv.most_similar('if', topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings\n",
    "\n",
    "Using Gensim, we can also access models that have been pre-trained on various datasets. The model ‘word2vec-google-news-300’ is used to create embeddings for sentences in the same manner as the previous step. \n",
    "While this served as an interesting investigation of word embeddings, using the embeddings from these two methods as features yielded worsened results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec_news = api.load(\"word2vec-google-news-300\") \n",
    "\n",
    "vectorized_sentences = vectorize(df['sentence'], model_word2vec_news)\n",
    "pretrained_embeddings = {}\n",
    "for i in range(vector_length):\n",
    "    pretrained_embeddings[i] = [val[i] for val in vectorized_sentences]\n",
    "\n",
    "model_word2vec_news.wv.most_similar('if', topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood and modality\n",
    "\n",
    "The Pattern library provides a simple way to extract these two features from sentences. Grammatical mood refers to the use of auxiliary verbs (e.g., could, would) and adverbs (e.g., definitely, maybe) to express uncertainty. The mood() function returns either INDICATIVE, IMPERATIVE, CONDITIONAL or SUBJUNCTIVE for a given parsed sentence. For this specific task, establishing whether a sentence’s mood is conditional could be useful to classify it as counterfactual. The modality() function returns the degree of certainty as a value between -1.0 and +1.0, where values > +0.5 represent facts. Adding modality as a feature slightly improved the model’s accuracy. While mood did seem like a promising feature to include as well (see distributions below), it did not improve the results further.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean modality score (0,1):\n",
      "0.14 -0.02\n",
      "Overall predicted moods (0,1):\n",
      "('conditional', 84.25) ('conditional', 88.33)\n",
      "('imperative', 0.85) ('imperative', 1.0)\n",
      "('indicative', 10.86) ('indicative', 2.0)\n",
      "('subjunctive', 4.04) ('subjunctive', 8.67)\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "counts_0 = {}\n",
    "counts_1 = {}\n",
    "mod0 = 0\n",
    "mod1 = 0\n",
    "for i, j in zip(df['sentence'], df['gold_label']):\n",
    "    s = parse(i)\n",
    "    s = Sentence(s)\n",
    "    if j == '0':\n",
    "        count_0 += 1\n",
    "        mod0 += modality(s)\n",
    "        counts_0[mood(s)] = counts_0.get(mood(s), 0) + 1        \n",
    "    elif j == '1':\n",
    "        count_1 += 1\n",
    "        mod1 += modality(s)\n",
    "        counts_1[mood(s)] = counts_1.get(mood(s), 0) + 1\n",
    "\n",
    "d0 = {k: round((v/count_0)*100, 2) for k, v in counts_0.items()}\n",
    "d1 = {k: round((v/count_1)*100, 2) for k, v in counts_1.items()}\n",
    "\n",
    "print(\"Mean modality score (0,1):\")\n",
    "print(round(mod0/count_0, 2), round(mod1/count_1, 2))\n",
    "print(\"Overall predicted moods (0,1):\")\n",
    "for i, j in zip(sorted(d0.items()), sorted(d1.items())):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léo\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode mood as a feature\n",
    "df['conditional'] = 0\n",
    "df['indicative'] = 0\n",
    "df['subjunctive'] = 0\n",
    "\n",
    "for idx, s in enumerate(df['sentence']):\n",
    "    s = parse(s)\n",
    "    s = Sentence(s)\n",
    "    if mood(s) == 'conditional':\n",
    "        df['conditional'].iloc[idx] = 1\n",
    "    elif mood(s) == 'indicative':\n",
    "        df['indicative'].iloc[idx] = 1\n",
    "    elif mood(s) == 'subjunctive':\n",
    "        df['subjunctive'].iloc[idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "To perform machine learning on our textual data, we need to turn each sentence into a numerical feature vector. Here are two methods we can use:\n",
    "\n",
    "- Bag-of-Words representation (BoW): This consists in counting the occurence of each token with no regard to syntactic structure. We collect a vocabulary of all occurring tokens, and then we attribute a score to each token, using its count or its frequency.   \n",
    "- TF-IDF: The problem with the BoW model is that it may attribute more importance to frequent words.  Rarer words specific to a domain are neglected while they could potentially contain useful information. To deal with this issue, a common method consists in scaling word frequency by how often they appear across all sentences, so that more frequent words are penalized. This method is called Term Frequency – Inverse Document Frequency. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(ngram_range=(1,3), max_features=3000, smooth_idf=True) \n",
    "Tfidf_vect = Tfidf_vect.fit_transform(df['sent_tok'])\n",
    "Tfidf_df = pd.DataFrame(Tfidf_vect.toarray())\n",
    "df = pd.concat([df, Tfidf_df.set_index(df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The following classifiers available in scikit-learn were tested: RandomForestClassifier, svm.SVC, MultinomialNB, SGDClassifier. Among these estimators, SGDClassifier performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3485\n",
      "           1       0.85      0.82      0.83      1481\n",
      "\n",
      "    accuracy                           0.90      4966\n",
      "   macro avg       0.89      0.88      0.88      4966\n",
      "weighted avg       0.90      0.90      0.90      4966\n",
      "\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3269   216  3485\n",
      "1           272  1209  1481\n",
      "All        3541  1425  4966\n"
     ]
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(df.iloc[:,5:], df['gold_label'],test_size=0.3)\n",
    "text_clf =  SGDClassifier(loss=\"hinge\", alpha=0.0001, penalty=\"elasticnet\", max_iter=1000).fit(Train_X, Train_Y) \n",
    "predicted = text_clf.predict(Test_X)\n",
    "\n",
    "print(metrics.classification_report(Test_Y, predicted, target_names=None))\n",
    "print(pd.crosstab(Test_Y, predicted, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the weights attributed to each keword by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('would', 1.2868696196246325)\n",
      "('say', 1.0187493868810535)\n",
      "('I', 0.88067557532815)\n",
      "(\"'s\", -0.39464025192397323)\n",
      "('may', 1.678167043264575)\n",
      "('Mr.', 0.19819411231247994)\n",
      "('even', -1.110390249471778)\n",
      "('year', -0.8314548069469684)\n",
      "('get', -0.6399906420151661)\n",
      "('take', -0.25161422223071106)\n"
     ]
    }
   ],
   "source": [
    "ngrams_coef = text_clf.coef_[0][-(len(ngrams_list)):]\n",
    "for i in zip(ngrams_list[:10], ngrams_coef[:10]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "The final step to make the predictions a tad more accurate is to tune the model’s hyperparameters. To do so, an exhaustive grid search was performed using GridSearchCV. GridSearchCV samples from a set of pre-defined hyperparameters and fits various models with different combinations of paramaters using k-fold cross-validation. The most accurate model can then be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd_param_grid = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00001],\n",
    "    'max_iter': [500, 1000] \n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(sgd, sgd_param_grid)\n",
    "clf.fit(train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                              | Precision      | Recall    | F1-score  |   |\n",
    "|------------------------------|----------------|-----------|-----------|---|\n",
    "| Raw text  - Count vectorizer | 0.83           | 0.68      | 0.70      |   |\n",
    "| **Raw text - TF-IDF**            | 0.82           | 0.68      | 0.73      |   |\n",
    "| **Adding subtask2 data**         | 0.85           | 0.82      | 0.84      |   |\n",
    "| *Preprocessing*                |                |           |           |   |\n",
    "| Lemmatization                | 0.83           | 0.80      | 0.82      |   |\n",
    "| **Tokenization**                 | 0.85           | 0.82      | 0.84      |   |\n",
    "| *Syntactic information*        |                |           |           |   |\n",
    "| **Merging Token_POS tag**        | 0.86           | 0.83      | 0.84      |   |\n",
    "| **Ngram range(1,3)**             | 0.88           | 0.85      | 0.86      |   |\n",
    "| **POS tags sequences**           | 0.88           | 0.87      | 0.87      |   |\n",
    "| *Semantic information*         |                |           |           |   |\n",
    "| Custom embeddings            | 0.85           | 0.79      | 0.80      |   |\n",
    "| Pretrained embeddings        | 0.86           | 0.80      | 0.81      |   |\n",
    "| **Modality**                     | 0.89           | 0.87      | 0.88      |   |\n",
    "| Mood                         | 0.87           | 0.87      | 0.87      |   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
